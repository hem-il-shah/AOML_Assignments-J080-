{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":982,"sourceType":"datasetVersion","datasetId":483}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T06:08:48.142595Z","iopub.execute_input":"2025-03-09T06:08:48.142902Z","iopub.status.idle":"2025-03-09T06:08:48.148280Z","shell.execute_reply.started":"2025-03-09T06:08:48.142879Z","shell.execute_reply":"2025-03-09T06:08:48.147563Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sms-spam-collection-dataset/spam.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')[['v1', 'v2']]\ndf.columns = ['label', 'text']\ndf['label'] = df['label'].map({'ham': 0, 'spam': 1})\n\ndef clean_text(text):\n    text = text.lower()  # Convert to lowercase\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n    return text\n\ndf['clean_text'] = df['text'].apply(clean_text)\n\n# Feature extraction\ndef train_models(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    models = {\n        \"Naive Bayes\": MultinomialNB(),\n        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n    }\n    \n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n        print(classification_report(y_test, y_pred))\n    \n    # Ensemble Model\n    ensemble = VotingClassifier(estimators=[('nb', models['Naive Bayes']), \n                                            ('rf', models['Random Forest']), \n                                            ('xgb', models['XGBoost'])], voting='hard')\n    ensemble.fit(X_train, y_train)\n    y_pred = ensemble.predict(X_test)\n    print(f\"Ensemble Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(classification_report(y_test, y_pred))\n\n# Apply BOW\nvectorizer = CountVectorizer()\nX_bow = vectorizer.fit_transform(df['text'])\nX_bow_clean = vectorizer.fit_transform(df['clean_text'])\ntrain_models(X_bow, df['label'])  # Without cleaning\ntrain_models(X_bow_clean, df['label'])  # With cleaning\n\n# Apply TF-IDF\ntfidf_vectorizer = TfidfVectorizer()\nX_tfidf = tfidf_vectorizer.fit_transform(df['text'])\nX_tfidf_clean = tfidf_vectorizer.fit_transform(df['clean_text'])\ntrain_models(X_tfidf, df['label'])  # Without cleaning\ntrain_models(X_tfidf_clean, df['label'])  # With cleaning\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T06:12:22.799734Z","iopub.execute_input":"2025-03-09T06:12:22.800094Z","iopub.status.idle":"2025-03-09T06:12:46.962999Z","shell.execute_reply.started":"2025-03-09T06:12:22.800065Z","shell.execute_reply":"2025-03-09T06:12:46.961633Z"}},"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.9785\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       965\n           1       0.91      0.93      0.92       150\n\n    accuracy                           0.98      1115\n   macro avg       0.95      0.96      0.95      1115\nweighted avg       0.98      0.98      0.98      1115\n\nRandom Forest Accuracy: 0.9749\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       965\n           1       1.00      0.81      0.90       150\n\n    accuracy                           0.97      1115\n   macro avg       0.99      0.91      0.94      1115\nweighted avg       0.98      0.97      0.97      1115\n\nXGBoost Accuracy: 0.9776\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99       965\n           1       0.96      0.87      0.91       150\n\n    accuracy                           0.98      1115\n   macro avg       0.97      0.93      0.95      1115\nweighted avg       0.98      0.98      0.98      1115\n\nEnsemble Accuracy: 0.9839\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       965\n           1       1.00      0.88      0.94       150\n\n    accuracy                           0.98      1115\n   macro avg       0.99      0.94      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\nNaive Bayes Accuracy: 0.9704\n              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98       965\n           1       0.88      0.91      0.89       150\n\n    accuracy                           0.97      1115\n   macro avg       0.93      0.94      0.94      1115\nweighted avg       0.97      0.97      0.97      1115\n\nRandom Forest Accuracy: 0.9686\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98       965\n           1       1.00      0.77      0.87       150\n\n    accuracy                           0.97      1115\n   macro avg       0.98      0.88      0.93      1115\nweighted avg       0.97      0.97      0.97      1115\n\nXGBoost Accuracy: 0.9776\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       965\n           1       0.97      0.86      0.91       150\n\n    accuracy                           0.98      1115\n   macro avg       0.97      0.93      0.95      1115\nweighted avg       0.98      0.98      0.98      1115\n\nEnsemble Accuracy: 0.9803\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       965\n           1       0.99      0.86      0.92       150\n\n    accuracy                           0.98      1115\n   macro avg       0.99      0.93      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\nNaive Bayes Accuracy: 0.9623\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98       965\n           1       1.00      0.72      0.84       150\n\n    accuracy                           0.96      1115\n   macro avg       0.98      0.86      0.91      1115\nweighted avg       0.96      0.96      0.96      1115\n\nRandom Forest Accuracy: 0.9767\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       965\n           1       1.00      0.83      0.91       150\n\n    accuracy                           0.98      1115\n   macro avg       0.99      0.91      0.95      1115\nweighted avg       0.98      0.98      0.98      1115\n\nXGBoost Accuracy: 0.9821\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       965\n           1       0.98      0.89      0.93       150\n\n    accuracy                           0.98      1115\n   macro avg       0.98      0.94      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\nEnsemble Accuracy: 0.9749\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       965\n           1       1.00      0.81      0.90       150\n\n    accuracy                           0.97      1115\n   macro avg       0.99      0.91      0.94      1115\nweighted avg       0.98      0.97      0.97      1115\n\nNaive Bayes Accuracy: 0.9507\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97       965\n           1       1.00      0.63      0.78       150\n\n    accuracy                           0.95      1115\n   macro avg       0.97      0.82      0.87      1115\nweighted avg       0.95      0.95      0.95      1115\n\nRandom Forest Accuracy: 0.9704\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98       965\n           1       1.00      0.78      0.88       150\n\n    accuracy                           0.97      1115\n   macro avg       0.98      0.89      0.93      1115\nweighted avg       0.97      0.97      0.97      1115\n\nXGBoost Accuracy: 0.9812\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       965\n           1       0.98      0.88      0.93       150\n\n    accuracy                           0.98      1115\n   macro avg       0.98      0.94      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\nEnsemble Accuracy: 0.9722\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98       965\n           1       1.00      0.79      0.88       150\n\n    accuracy                           0.97      1115\n   macro avg       0.98      0.90      0.93      1115\nweighted avg       0.97      0.97      0.97      1115\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}