{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17000,"databundleVersionId":895292,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T18:11:52.362387Z","iopub.execute_input":"2025-03-08T18:11:52.362795Z","iopub.status.idle":"2025-03-08T18:11:52.371515Z","shell.execute_reply.started":"2025-03-08T18:11:52.362756Z","shell.execute_reply":"2025-03-08T18:11:52.370042Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cat-in-the-dat-ii/sample_submission.csv\n/kaggle/input/cat-in-the-dat-ii/train.csv\n/kaggle/input/cat-in-the-dat-ii/test.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\n\n# Load Data\ndf = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/train.csv')\ntest_df = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/test.csv')\n\n# Data Overview\nprint(df.info())\nprint(df.head())\n\n# Feature Engineering\n# 1. Handling Missing Values\nimputer = SimpleImputer(strategy='most_frequent')\ndf_features = df.drop(['id', 'target'], axis=1)\ntest_features = test_df.drop(['id'], axis=1)\n\ndf[df_features.columns] = imputer.fit_transform(df_features)\ntest_df[test_features.columns] = imputer.transform(test_features)\n\n# Ensure column names are strings\ndf.columns = df.columns.astype(str)\ntest_df.columns = test_df.columns.astype(str)\n\n# 2. Encoding Techniques\n# Binary Encoding\nfor col in ['bin_3', 'bin_4']:\n    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n    test_df[col] = LabelEncoder().fit_transform(test_df[col].astype(str))\n\n# One-Hot Encoding for Nominal Categorical Features\nohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nnominal_cols = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\ndf_nom = pd.DataFrame(ohe.fit_transform(df[nominal_cols]))\ntest_nom = pd.DataFrame(ohe.transform(test_df[nominal_cols]))\n\n# Combine Encoded Features\ndf = pd.concat([df, df_nom], axis=1)\ntest_df = pd.concat([test_df, test_nom], axis=1)\ndf.drop(nominal_cols, axis=1, inplace=True)\ntest_df.drop(nominal_cols, axis=1, inplace=True)\n\n# Convert all column names to strings after one-hot encoding\ndf.columns = df.columns.astype(str)\ntest_df.columns = test_df.columns.astype(str)\n\n# 3. Ordinal Encoding\nordinal_cols = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\nfor col in ordinal_cols:\n    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n    test_df[col] = LabelEncoder().fit_transform(test_df[col].astype(str))\n\n# 4. Force Numeric Conversion and Imputation\nfor col in df.columns.drop(['id', 'target']):\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n    test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n\nimputer = SimpleImputer(strategy='mean')\ndf[df.columns.drop(['id', 'target'])] = imputer.fit_transform(df.drop(['id', 'target'], axis=1))\ntest_df[test_df.columns.drop(['id'])] = imputer.transform(test_df.drop(['id'], axis=1))\n\n# 5. Feature Scaling\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(df.drop(['id', 'target'], axis=1))\ndf_scaled = pd.DataFrame(scaled_features, columns=df.columns.drop(['id', 'target']))\n\ntest_scaled_features = scaler.transform(test_df.drop('id', axis=1))\ntest_scaled = pd.DataFrame(test_scaled_features, columns=test_df.columns.drop('id'))\n\n# Combine ID and Target Back\ndf = pd.concat([df[['id', 'target']], df_scaled], axis=1)\ntest_df = pd.concat([test_df[['id']], test_scaled], axis=1)\n\n# Splitting the data\nX = df.drop(['id', 'target'], axis=1)\ny = df['target']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Verify no NaNs exist\nprint(f\"NaN values in X_train: {np.isnan(X_train).sum().sum()}\")\n\n# Model Building and Tuning\ndef build_model(model, params, search_type='grid'):\n    if search_type == 'grid':\n        search = GridSearchCV(model, params, cv=5, scoring='roc_auc')\n    else:\n        search = RandomizedSearchCV(model, params, n_iter=20, cv=5, scoring='roc_auc', random_state=42)\n        \n    search.fit(X_train, y_train)\n    best_model = search.best_estimator_\n        \n    y_pred = best_model.predict(X_valid)\n    print(f\"{model.__class__.__name__} Accuracy: {accuracy_score(y_valid, y_pred):.4f}\")\n    print(f\"{model.__class__.__name__} AUC-ROC: {roc_auc_score(y_valid, y_pred):.4f}\")\n        \n    return best_model\n\n# Random Forest with GridSearchCV (using HistGradientBoostingClassifier)\nrf_params = {\n    'max_depth': [None, 10, 20],\n    'min_samples_leaf': [2, 5, 10]\n}\nrf_model = build_model(HistGradientBoostingClassifier(), rf_params, 'grid')\n\n# XGBoost with RandomizedSearchCV\nxgb_params = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\nxgb_model = build_model(xgb.XGBClassifier(), xgb_params, 'random')\n\n# LightGBM with GridSearchCV\nlgb_params = {\n    'n_estimators': [100, 200],\n    'max_depth': [-1, 10, 20],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\nlgb_model = build_model(lgb.LGBMClassifier(), lgb_params, 'grid')\n\n# CatBoost with RandomizedSearchCV\ncb_params = {\n    'iterations': [100, 200, 300],\n    'depth': [4, 6, 8],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\ncb_model = build_model(cb.CatBoostClassifier(verbose=0), cb_params, 'random')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T18:15:40.283792Z","iopub.execute_input":"2025-03-08T18:15:40.284209Z","iopub.status.idle":"2025-03-08T19:06:51.824259Z","shell.execute_reply.started":"2025-03-08T18:15:40.284174Z","shell.execute_reply":"2025-03-08T19:06:51.822970Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 600000 entries, 0 to 599999\nData columns (total 25 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   id      600000 non-null  int64  \n 1   bin_0   582106 non-null  float64\n 2   bin_1   581997 non-null  float64\n 3   bin_2   582070 non-null  float64\n 4   bin_3   581986 non-null  object \n 5   bin_4   581953 non-null  object \n 6   nom_0   581748 non-null  object \n 7   nom_1   581844 non-null  object \n 8   nom_2   581965 non-null  object \n 9   nom_3   581879 non-null  object \n 10  nom_4   581965 non-null  object \n 11  nom_5   582222 non-null  object \n 12  nom_6   581869 non-null  object \n 13  nom_7   581997 non-null  object \n 14  nom_8   582245 non-null  object \n 15  nom_9   581927 non-null  object \n 16  ord_0   581712 non-null  float64\n 17  ord_1   581959 non-null  object \n 18  ord_2   581925 non-null  object \n 19  ord_3   582084 non-null  object \n 20  ord_4   582070 non-null  object \n 21  ord_5   582287 non-null  object \n 22  day     582048 non-null  float64\n 23  month   582012 non-null  float64\n 24  target  600000 non-null  int64  \ndtypes: float64(6), int64(2), object(17)\nmemory usage: 114.4+ MB\nNone\n   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n\n   ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day month  \\\n0  ...  02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   3.0   \n1  ...  f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   7.0   \n2  ...        NaN   3.0          NaN  Freezing     n     P     eN  5.0   9.0   \n3  ...  f9d456e57   1.0       Novice  Lava Hot     a     C    NaN  3.0   3.0   \n4  ...  c5361037c   3.0  Grandmaster      Cold     h     C     OZ  5.0  12.0   \n\n  target  \n0      0  \n1      0  \n2      0  \n3      0  \n4      0  \n\n[5 rows x 25 columns]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1072: RuntimeWarning: invalid value encountered in subtract\n  new_unnormalized_variance -= correction**2 / new_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:87: RuntimeWarning: invalid value encountered in less_equal\n  return var <= upper_bound\n","output_type":"stream"},{"name":"stdout","text":"NaN values in X_train: 480000\nHistGradientBoostingClassifier Accuracy: 0.8196\nHistGradientBoostingClassifier AUC-ROC: 0.5446\nXGBClassifier Accuracy: 0.8206\nXGBClassifier AUC-ROC: 0.5495\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081847 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077253 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075783 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077317 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076243 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081057 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074541 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075828 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078208 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075300 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075505 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076749 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078145 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076288 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075613 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076863 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077605 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075736 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076963 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075839 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075366 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075639 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075618 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076276 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076288 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076352 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089793 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075467 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076510 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075418 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076812 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076171 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075308 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076851 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075538 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077366 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075304 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076474 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075453 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075014 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082163 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077362 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087395 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076594 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081563 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076502 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077070 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096404 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078354 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089556 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075201 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076018 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076783 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078277 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074978 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075069 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087229 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075155 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077605 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098411 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076090 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078002 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076845 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076688 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075838 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077157 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075208 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075320 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076642 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075988 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074100 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076603 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076258 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074852 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108883 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082272 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078169 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075428 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077732 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076025 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075811 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076290 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074380 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076581 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075683 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075816 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71971, number of negative: 312029\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076852 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187424 -> initscore=-1.466833\n[LightGBM] [Info] Start training from score -1.466833\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076142 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104742 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 71970, number of negative: 312030\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077188 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 384000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187422 -> initscore=-1.466850\n[LightGBM] [Info] Start training from score -1.466850\n[LightGBM] [Info] Number of positive: 89963, number of negative: 390037\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095494 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 380\n[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 42\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187423 -> initscore=-1.466843\n[LightGBM] [Info] Start training from score -1.466843\nLGBMClassifier Accuracy: 0.8204\nLGBMClassifier AUC-ROC: 0.5536\nCatBoostClassifier Accuracy: 0.8205\nCatBoostClassifier AUC-ROC: 0.5535\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}