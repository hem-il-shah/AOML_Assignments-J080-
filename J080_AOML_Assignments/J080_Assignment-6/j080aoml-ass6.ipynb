{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:36:29.792052Z","iopub.execute_input":"2025-03-09T12:36:29.792591Z","iopub.status.idle":"2025-03-09T12:36:30.349963Z","shell.execute_reply.started":"2025-03-09T12:36:29.792513Z","shell.execute_reply":"2025-03-09T12:36:30.348230Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# from sklearn.model_selection import train_test_split, GridSearchCV\n# from sklearn.svm import SVC\n# from sklearn.metrics import accuracy_score\n# from sklearn.preprocessing import StandardScaler\n# import struct\n\n# def load_ubyte(image_path, label_path):\n#     with open(label_path, 'rb') as label_file, open(image_path, 'rb') as image_file:\n#         magic_label, num_labels = struct.unpack('>II', label_file.read(8))\n#         magic_image, num_images, rows, cols = struct.unpack('>IIII', image_file.read(16))\n\n#         labels = np.frombuffer(label_file.read(), dtype=np.uint8)\n#         images = np.frombuffer(image_file.read(), dtype=np.uint8).reshape(num_images, rows * cols).astype(np.float32)\n#         return images, labels\n\n# # Load the Fashion-MNIST dataset from UByte files\n# x_train, y_train = load_ubyte('/kaggle/input/fashionmnist/train-images-idx3-ubyte', '/kaggle/input/fashionmnist/train-labels-idx1-ubyte')\n# x_test, y_test = load_ubyte('/kaggle/input/fashionmnist/t10k-images-idx3-ubyte', '/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte')\n\n# # Scale the data\n# scaler = StandardScaler()\n# x_train = scaler.fit_transform(x_train)\n# x_test = scaler.transform(x_test)\n\n# # Split the data into training and validation sets\n# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n\n# # 1. Linear Kernel\n# print(\"Training SVM with Linear Kernel...\")\n# param_grid_linear = {'C': [0.1, 1, 10, 100]}\n# grid_search_linear = GridSearchCV(SVC(kernel='linear'), param_grid_linear, cv=3, n_jobs=-1, verbose=1)\n# grid_search_linear.fit(x_train, y_train)\n\n# best_C_linear = grid_search_linear.best_params_['C']\n# best_svm_linear = SVC(kernel='linear', C=best_C_linear)\n# best_svm_linear.fit(x_train, y_train)\n# y_pred_linear = best_svm_linear.predict(x_val)\n# accuracy_linear = accuracy_score(y_val, y_pred_linear)\n\n# print(f\"Best C (Linear): {best_C_linear}\")\n# print(f\"Validation Accuracy (Linear): {accuracy_linear}\")\n\n# # 2. Polynomial Kernel\n# print(\"\\nTraining SVM with Polynomial Kernel...\")\n# param_grid_poly = {'C': [0.1, 1, 10], 'degree': [2, 3, 4]}\n# grid_search_poly = GridSearchCV(SVC(kernel='poly'), param_grid_poly, cv=3, n_jobs=-1, verbose=1)\n# grid_search_poly.fit(x_train, y_train)\n\n# best_C_poly = grid_search_poly.best_params_['C']\n# best_degree_poly = grid_search_poly.best_params_['degree']\n# best_svm_poly = SVC(kernel='poly', C=best_C_poly, degree=best_degree_poly)\n# best_svm_poly.fit(x_train, y_train)\n# y_pred_poly = best_svm_poly.predict(x_val)\n# accuracy_poly = accuracy_score(y_val, y_pred_poly)\n\n# print(f\"Best C (Polynomial): {best_C_poly}\")\n# print(f\"Best Degree (Polynomial): {best_degree_poly}\")\n# print(f\"Validation Accuracy (Polynomial): {accuracy_poly}\")\n\n# # 3. RBF Kernel\n# print(\"\\nTraining SVM with RBF Kernel...\")\n# param_grid_rbf = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1]}\n# grid_search_rbf = GridSearchCV(SVC(kernel='rbf'), param_grid_rbf, cv=3, n_jobs=-1, verbose=1)\n# grid_search_rbf.fit(x_train, y_train)\n\n# best_C_rbf = grid_search_rbf.best_params_['C']\n# best_gamma_rbf = grid_search_rbf.best_params_['gamma']\n# best_svm_rbf = SVC(kernel='rbf', C=best_C_rbf, gamma=best_gamma_rbf)\n# best_svm_rbf.fit(x_train, y_train)\n# y_pred_rbf = best_svm_rbf.predict(x_val)\n# accuracy_rbf = accuracy_score(y_val, y_pred_rbf)\n\n# print(f\"Best C (RBF): {best_C_rbf}\")\n# print(f\"Best Gamma (RBF): {best_gamma_rbf}\")\n# print(f\"Validation Accuracy (RBF): {accuracy_rbf}\")\n\n# # Evaluate on test set with best rbf model.\n# y_test_pred_rbf = best_svm_rbf.predict(x_test)\n# test_accuracy_rbf = accuracy_score(y_test,y_test_pred_rbf)\n# print(f\"\\nTest Accuracy (RBF): {test_accuracy_rbf}\")\n\n'''\n\n'''\n\n# import numpy as np\n# import pandas as pd\n# from sklearn.model_selection import train_test_split, GridSearchCV\n# from sklearn.svm import SVC\n# from sklearn.metrics import accuracy_score\n# from sklearn.preprocessing import StandardScaler\n# import struct\n\n# def load_ubyte(image_path, label_path):\n#     with open(label_path, 'rb') as label_file, open(image_path, 'rb') as image_file:\n#         magic_label, num_labels = struct.unpack('>II', label_file.read(8))\n#         magic_image, num_images, rows, cols = struct.unpack('>IIII', image_file.read(16))\n\n#         labels = np.frombuffer(label_file.read(), dtype=np.uint8)\n#         images = np.frombuffer(image_file.read(), dtype=np.uint8).reshape(num_images, rows * cols).astype(np.float32)\n#         return images, labels\n\n# Load the Fashion-MNIST dataset from UByte files\n# x_train, y_train = load_ubyte('/kaggle/input/fashionmnist/train-images-idx3-ubyte', '/kaggle/input/fashionmnist/train-labels-idx1-ubyte')\n# x_test, y_test = load_ubyte('/kaggle/input/fashionmnist/t10k-images-idx3-ubyte', '/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte')\n\n# # Scale the data\n# scaler = StandardScaler()\n# x_train = scaler.fit_transform(x_train)\n# x_test = scaler.transform(x_test)\n\n# # Split the data into training and validation sets\n# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n\n# # 1. Linear Kernel\n# print(\"Training SVM with Linear Kernel...\")\n# param_grid_linear = {'C': [0.1, 1, 10]}  # Reduced parameter grid\n# grid_search_linear = GridSearchCV(SVC(kernel='linear'), param_grid_linear, cv=2, n_jobs=-1, verbose=1)  # Reduced cv\n# grid_search_linear.fit(x_train, y_train)\n\n# best_C_linear = grid_search_linear.best_params_['C']\n# best_svm_linear = SVC(kernel='linear', C=best_C_linear)\n# best_svm_linear.fit(x_train, y_train)\n# y_pred_linear = best_svm_linear.predict(x_val)\n# accuracy_linear = accuracy_score(y_val, y_pred_linear)\n\n# print(f\"Best C (Linear): {best_C_linear}\")\n# print(f\"Validation Accuracy (Linear): {accuracy_linear}\")\n\n# # 2. Polynomial Kernel\n# print(\"\\nTraining SVM with Polynomial Kernel...\")\n# param_grid_poly = {'C': [0.1, 1], 'degree': [2, 3]}  # Reduced parameter grid\n# grid_search_poly = GridSearchCV(SVC(kernel='poly'), param_grid_poly, cv=2, n_jobs=-1, verbose=1)  # Reduced cv\n# grid_search_poly.fit(x_train, y_train)\n\n# best_C_poly = grid_search_poly.best_params_['C']\n# best_degree_poly = grid_search_poly.best_params_['degree']\n# best_svm_poly = SVC(kernel='poly', C=best_C_poly, degree=best_degree_poly)\n# best_svm_poly.fit(x_train, y_train)\n# y_pred_poly = best_svm_poly.predict(x_val)\n# accuracy_poly = accuracy_score(y_val, y_pred_poly)\n\n# print(f\"Best C (Polynomial): {best_C_poly}\")\n# print(f\"Best Degree (Polynomial): {best_degree_poly}\")\n# print(f\"Validation Accuracy (Polynomial): {accuracy_poly}\")\n\n# # 3. RBF Kernel\n# print(\"\\nTraining SVM with RBF Kernel...\")\n# param_grid_rbf = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1]}  # Reduced parameter grid\n# grid_search_rbf = GridSearchCV(SVC(kernel='rbf'), param_grid_rbf, cv=2, n_jobs=-1, verbose=1)  # Reduced cv\n# grid_search_rbf.fit(x_train, y_train)\n\n# best_C_rbf = grid_search_rbf.best_params_['C']\n# best_gamma_rbf = grid_search_rbf.best_params_['gamma']\n# best_svm_rbf = SVC(kernel='rbf', C=best_C_rbf, gamma=best_gamma_rbf)\n# best_svm_rbf.fit(x_train, y_train)\n# y_pred_rbf = best_svm_rbf.predict(x_val)\n# accuracy_rbf = accuracy_score(y_val, y_pred_rbf)\n\n# print(f\"Best C (RBF): {best_C_rbf}\")\n# print(f\"Best Gamma (RBF): {best_gamma_rbf}\")\n# print(f\" Validation Accuracy (RBF): {accuracy_rbf}\")\n\n# # Evaluate on test set with best rbf model.\n# y_test_pred_rbf = best_svm_rbf.predict(x_test)\n# test_accuracy_rbf = accuracy_score(y_test, y_test_pred_rbf)\n# print(f\"\\nTest Accuracy (RBF): {test_accuracy_rbf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:36:30.351582Z","iopub.execute_input":"2025-03-09T12:36:30.352226Z","iopub.status.idle":"2025-03-09T12:36:30.364629Z","shell.execute_reply.started":"2025-03-09T12:36:30.352184Z","shell.execute_reply":"2025-03-09T12:36:30.362957Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'\\n\\n'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# # Import Libraries\n# import numpy as np\n# import pandas as pd\n# from sklearn import datasets\n# from sklearn.model_selection import train_test_split, GridSearchCV\n# from sklearn.svm import SVC\n# from sklearn.metrics import classification_report, accuracy_score\n\n# # Load Fashion MNIST dataset\n# fashion_mnist = datasets.fetch_openml('Fashion-MNIST', version=1)\n# X = fashion_mnist.data\n# y = fashion_mnist.target.astype(int)  # Convert target to integer type\n\n# # Split Data into Training and Testing Sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # 1. Train SVM Model with Linear Kernel\n# print(\"Training SVM with Linear Kernel...\")\n# svm_linear = SVC(kernel='linear')\n\n# # Use GridSearch to find the best value for C\n# param_grid_linear = {'C': [0.1, 1, 10, 100, 1000]}\n# grid_search_linear = GridSearchCV(svm_linear, param_grid_linear, cv=5)\n# grid_search_linear.fit(X_train, y_train)\n\n# # Best C value for Linear Kernel\n# best_C_linear = grid_search_linear.best_params_['C']\n# print(f\"Best C for Linear Kernel: {best_C_linear}\")\n\n# # Evaluate the model\n# linear_model = grid_search_linear.best_estimator_\n# y_pred_linear = linear_model.predict(X_test)\n# print(\"Linear Kernel Classification Report:\")\n# print(classification_report(y_test, y_pred_linear))\n\n# # 2. Train SVM with Polynomial Kernel\n# print(\"\\nTraining SVM with Polynomial Kernel...\")\n# svm_poly = SVC(kernel='poly')\n\n# # Use GridSearch to find the best value for polynomial degree and C\n# param_grid_poly = {'C': [0.1, 1, 10, 100, 1000], 'degree': [2, 3, 4, 5]}\n# grid_search_poly = GridSearchCV(svm_poly, param_grid_poly, cv=5)\n# grid_search_poly.fit(X_train, y_train)\n\n# # Best parameters for Polynomial Kernel\n# best_params_poly = grid_search_poly.best_params_\n# print(f\"Best C for Polynomial Kernel: {best_params_poly['C']}, Best Degree: {best_params_poly['degree']}\")\n\n# # Evaluate the model\n# poly_model = grid_search_poly.best_estimator_\n# y_pred_poly = poly_model.predict(X_test)\n# print(\"Polynomial Kernel Classification Report:\")\n# print(classification_report(y_test, y_pred_poly))\n\n# # 3. Train SVM with RBF Kernel\n# print(\"\\nTraining SVM with RBF Kernel...\")\n# svm_rbf = SVC(kernel='rbf')\n\n# # Use GridSearch to find the best values for gamma and C\n# param_grid_rbf = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.01, 0.1, 1, 10]}\n# grid_search_rbf = GridSearchCV(svm_rbf, param_grid_rbf, cv=5)\n# grid_search_rbf.fit(X_train, y_train)\n\n# # Best parameters for RBF Kernel\n# best_params_rbf = grid_search_rbf.best_params_\n# print(f\"Best C for RBF Kernel: {best_params_rbf['C']}, Best Gamma: {best_params_rbf['gamma']}\")\n\n# # Evaluate the model\n# rbf_model = grid_search_rbf.best_estimator_\n# y_pred_rbf = rbf_model.predict(X_test)\n# print(\"RBF Kernel Classification Report:\")\n# print(classification_report(y_test, y_pred_rbf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:36:30.367355Z","iopub.execute_input":"2025-03-09T12:36:30.367977Z","iopub.status.idle":"2025-03-09T12:36:30.394716Z","shell.execute_reply.started":"2025-03-09T12:36:30.367914Z","shell.execute_reply":"2025-03-09T12:36:30.393049Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:36:30.546049Z","iopub.execute_input":"2025-03-09T12:36:30.546492Z","iopub.status.idle":"2025-03-09T12:36:34.718176Z","shell.execute_reply.started":"2025-03-09T12:36:30.546458Z","shell.execute_reply":"2025-03-09T12:36:34.716756Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n\nX_train = X_train.reshape(X_train.shape[0], -1)\nX_test = X_test.reshape(X_test.shape[0], -1)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:36:34.719757Z","iopub.execute_input":"2025-03-09T12:36:34.720355Z","iopub.status.idle":"2025-03-09T12:36:36.233819Z","shell.execute_reply.started":"2025-03-09T12:36:34.720322Z","shell.execute_reply":"2025-03-09T12:36:36.230663Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.1, random_state=80\n)\n\nparam_grid_linear = {\"C\": [0.1, 1, 10, 100]}\nsvm_linear = GridSearchCV(svm.SVC(kernel=\"linear\"), param_grid_linear, cv=3, n_jobs=-1)\nsvm_linear.fit(X_train, y_train)\nprint(\"Best C for linear kernel:\", svm_linear.best_params_[\"C\"])\n\nparam_grid_poly = {\"C\": [0.1, 1, 10], \"degree\": [2, 3, 4]}\nsvm_poly = GridSearchCV(svm.SVC(kernel=\"poly\"), param_grid_poly, cv=3, n_jobs=-1)\nsvm_poly.fit(X_train, y_train)\nprint(\"Best parameters for polynomial kernel:\", svm_poly.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:36:36.235753Z","iopub.execute_input":"2025-03-09T12:36:36.236461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"param_grid_rbf = {\"C\": [0.1, 1, 10], \"gamma\": [\"scale\", 0.01, 0.1, 1]}\nsvm_rbf = GridSearchCV(svm.SVC(kernel=\"rbf\"), param_grid_rbf, cv=3, n_jobs=-1)\nsvm_rbf.fit(X_train, y_train)\nprint(\"Best parameters for RBF kernel:\", svm_rbf.best_params_)\n\nmodels = {\n    \"Linear\": svm_linear.best_estimator_,\n    \"Polynomial\": svm_poly.best_estimator_,\n    \"RBF\": svm_rbf.best_estimator_,\n}\nfor name, model in models.items():\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    print(f\"{name} SVM Accuracy: {acc:.4f}\")\n    print(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}